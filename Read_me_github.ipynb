{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4C8YfxPWdB1h6uUcYIya6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fridaruh/Agentes/blob/main/Read_me_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj-Ap-RFBjs5",
        "outputId": "ff413f95-7a78-4723-efd2-d29321fdd056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen\n",
            "  Downloading pyautogen-0.2.27-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache (from pyautogen)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker (from pyautogen)\n",
            "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flaml (from pyautogen)\n",
            "  Downloading FLAML-2.1.2-py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (1.25.2)\n",
            "Collecting openai>=1.3 (from pyautogen)\n",
            "  Downloading openai-1.28.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.7.1)\n",
            "Collecting python-dotenv (from pyautogen)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.4.0)\n",
            "Collecting tiktoken (from pyautogen)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (2.18.2)\n",
            "Requirement already satisfied: packaging>=14.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (24.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen) (3.3.2)\n",
            "Installing collected packages: python-dotenv, h11, flaml, diskcache, tiktoken, httpcore, docker, httpx, openai, pyautogen\n",
            "Successfully installed diskcache-5.6.3 docker-7.0.0 flaml-2.1.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.28.1 pyautogen-0.2.27 python-dotenv-1.0.1 tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyautogen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "import autogen\n",
        "from autogen.agentchat import AssistantAgent, UserProxyAgent\n",
        "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
        "\n",
        "config_list = autogen.config_list_from_json(\n",
        "    \"OAI_CONFIG_LIST.txt\",\n",
        "    file_location=\".\",\n",
        "    filter_dict={\n",
        "        \"model\": [\"gpt-3.5-turbo\", \"gpt-35-turbo\", \"gpt-4\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-turbo\"],\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "yyFvVXOTCB42"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definición de Agentes"
      ],
      "metadata": {
        "id": "aOA6kRrjFp2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Asistente"
      ],
      "metadata": {
        "id": "m6F79FsrGZ2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an AssistantAgent named \"assistant\"\n",
        "assistant = autogen.AssistantAgent(\n",
        "    name = \"assistant\",\n",
        "    llm_config={\n",
        "        \"seed\": 42, #seed for caching and reproducibility\n",
        "        \"config_list\": config_list, #API Key call and other configurations\n",
        "        \"temperature\": 0, #temperature for sampling 0 is very objective, 1 is totally creative\n",
        "      },\n",
        ")"
      ],
      "metadata": {
        "id": "ceTxqjE7Ccks"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User Proxy Agent"
      ],
      "metadata": {
        "id": "VdOtUp9HGcjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los agentes userproxy de OpenAI son utilizados principalmente para manejar y gestionar las solicitudes de los usuarios hacia los modelos de inteligencia artificial, como ChatGPT. Estos agentes actúan como intermediarios entre los usuarios y los modelos, asegurando que las solicitudes se manejen de manera eficiente y segura."
      ],
      "metadata": {
        "id": "P8OChbjPGYCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a UserProxyAgent instance named \"user_proxy\"\n",
        "\n",
        "user_proxy = autogen.AssistantAgent(\n",
        "    name=\"user_proxy\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    max_consecutive_auto_reply=10,\n",
        "    is_termination_msg= lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
        "    code_execution_config= {\n",
        "        \"work_dir\": \"coding\",\n",
        "        \"user_docker\": False, #Set to true or image name like \"python:3\" to use docker\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "a-sowxsJFtQI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The assistant receives a message from the usser_proxy, which contains the task description-\n",
        "\n",
        "objetivo = input(\"¿Cuál es el objetivo que debe cumplir el agente?\")\n",
        "\n",
        "user_proxy.initiate_chat(\n",
        "    assistant,\n",
        "    message = objetivo,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmeCXtiGHSWx",
        "outputId": "e80d9317-f0ec-4387-f8a8-217e94c25410"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Cuál es el objetivo que debe cumplir el agente?Genera el documento READ_ME.md para un repositorio de Github donde se están enseñando a usar los Agentes de ChatGPT\n",
            "user_proxy (to assistant):\n",
            "\n",
            "Genera el documento READ_ME.md para un repositorio de Github donde se están enseñando a usar los Agentes de ChatGPT\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to user_proxy):\n",
            "\n",
            "# filename: README.md\n",
            "\n",
            "```markdown\n",
            "# ChatGPT Agent Tutorial\n",
            "\n",
            "Bienvenido a este repositorio de GitHub donde aprenderás a usar los Agentes de ChatGPT.\n",
            "\n",
            "## Descripción\n",
            "\n",
            "Este repositorio está diseñado para enseñarte cómo utilizar los Agentes de ChatGPT. Los Agentes de ChatGPT son modelos de lenguaje de inteligencia artificial desarrollados por OpenAI que pueden generar respuestas humanas a las entradas de texto.\n",
            "\n",
            "## Contenido\n",
            "\n",
            "Este repositorio contiene:\n",
            "\n",
            "- Tutoriales paso a paso sobre cómo utilizar los Agentes de ChatGPT.\n",
            "- Ejemplos de código para ayudarte a entender cómo funcionan los Agentes de ChatGPT.\n",
            "- Recursos adicionales para aprender más sobre los Agentes de ChatGPT.\n",
            "\n",
            "## Cómo empezar\n",
            "\n",
            "Para empezar, clona este repositorio en tu máquina local y sigue los tutoriales en el orden en que se presentan.\n",
            "\n",
            "## Contribuir\n",
            "\n",
            "Si tienes alguna sugerencia o mejora, no dudes en hacer un pull request. Apreciamos todas las contribuciones.\n",
            "\n",
            "## Licencia\n",
            "\n",
            "Este proyecto está bajo la licencia MIT. Consulta el archivo LICENSE para más detalles.\n",
            "\n",
            "## Contacto\n",
            "\n",
            "Si tienes alguna pregunta, no dudes en contactarnos.\n",
            "\n",
            "¡Disfruta aprendiendo sobre los Agentes de ChatGPT!\n",
            "```\n",
            "\n",
            "Por favor, guarda este contenido en un archivo llamado README.md en la raíz de tu repositorio de GitHub. Este archivo actuará como la página de inicio de tu repositorio y proporcionará información a los visitantes sobre el propósito y el contenido de tu repositorio.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is markdown)...\n",
            "user_proxy (to assistant):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "unknown language markdown\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to user_proxy):\n",
            "\n",
            "Mis disculpas por la confusión. Parece que hubo un malentendido. No necesitas ejecutar el bloque de código anterior. En su lugar, debes copiar el contenido y pegarlo en un archivo llamado README.md en la raíz de tu repositorio de GitHub.\n",
            "\n",
            "Aquí están los pasos que puedes seguir:\n",
            "\n",
            "1. Abre tu editor de texto preferido (como Notepad, Sublime Text, Atom, etc.).\n",
            "2. Copia el contenido del bloque de código anterior.\n",
            "3. Pega el contenido en tu editor de texto.\n",
            "4. Guarda el archivo con el nombre README.md en la raíz de tu repositorio de GitHub.\n",
            "\n",
            "Una vez que hayas hecho esto, el archivo README.md se mostrará en la página principal de tu repositorio en GitHub, proporcionando información a los visitantes sobre el propósito y el contenido de tu repositorio.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "user_proxy (to assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to user_proxy):\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': 'Genera el documento READ_ME.md para un repositorio de Github donde se están enseñando a usar los Agentes de ChatGPT', 'role': 'assistant'}, {'content': '# filename: README.md\\n\\n```markdown\\n# ChatGPT Agent Tutorial\\n\\nBienvenido a este repositorio de GitHub donde aprenderás a usar los Agentes de ChatGPT.\\n\\n## Descripción\\n\\nEste repositorio está diseñado para enseñarte cómo utilizar los Agentes de ChatGPT. Los Agentes de ChatGPT son modelos de lenguaje de inteligencia artificial desarrollados por OpenAI que pueden generar respuestas humanas a las entradas de texto.\\n\\n## Contenido\\n\\nEste repositorio contiene:\\n\\n- Tutoriales paso a paso sobre cómo utilizar los Agentes de ChatGPT.\\n- Ejemplos de código para ayudarte a entender cómo funcionan los Agentes de ChatGPT.\\n- Recursos adicionales para aprender más sobre los Agentes de ChatGPT.\\n\\n## Cómo empezar\\n\\nPara empezar, clona este repositorio en tu máquina local y sigue los tutoriales en el orden en que se presentan.\\n\\n## Contribuir\\n\\nSi tienes alguna sugerencia o mejora, no dudes en hacer un pull request. Apreciamos todas las contribuciones.\\n\\n## Licencia\\n\\nEste proyecto está bajo la licencia MIT. Consulta el archivo LICENSE para más detalles.\\n\\n## Contacto\\n\\nSi tienes alguna pregunta, no dudes en contactarnos.\\n\\n¡Disfruta aprendiendo sobre los Agentes de ChatGPT!\\n```\\n\\nPor favor, guarda este contenido en un archivo llamado README.md en la raíz de tu repositorio de GitHub. Este archivo actuará como la página de inicio de tu repositorio y proporcionará información a los visitantes sobre el propósito y el contenido de tu repositorio.', 'role': 'user'}, {'content': 'exitcode: 1 (execution failed)\\nCode output: \\nunknown language markdown', 'role': 'assistant'}, {'content': 'Mis disculpas por la confusión. Parece que hubo un malentendido. No necesitas ejecutar el bloque de código anterior. En su lugar, debes copiar el contenido y pegarlo en un archivo llamado README.md en la raíz de tu repositorio de GitHub.\\n\\nAquí están los pasos que puedes seguir:\\n\\n1. Abre tu editor de texto preferido (como Notepad, Sublime Text, Atom, etc.).\\n2. Copia el contenido del bloque de código anterior.\\n3. Pega el contenido en tu editor de texto.\\n4. Guarda el archivo con el nombre README.md en la raíz de tu repositorio de GitHub.\\n\\nUna vez que hayas hecho esto, el archivo README.md se mostrará en la página principal de tu repositorio en GitHub, proporcionando información a los visitantes sobre el propósito y el contenido de tu repositorio.', 'role': 'user'}, {'content': '', 'role': 'assistant'}, {'content': 'TERMINATE', 'role': 'user'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0.105, 'gpt-4-0613': {'cost': 0.105, 'prompt_tokens': 2430, 'completion_tokens': 535, 'total_tokens': 2965}}, 'usage_excluding_cached_inference': {'total_cost': 0.105, 'gpt-4-0613': {'cost': 0.105, 'prompt_tokens': 2430, 'completion_tokens': 535, 'total_tokens': 2965}}}, human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NWpnK1VaHwVs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}